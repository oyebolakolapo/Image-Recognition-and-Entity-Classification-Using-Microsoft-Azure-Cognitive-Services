# -*- coding: utf-8 -*-
"""Parsing_Image_to_Text_and_Entity_Classification_using_MS_Azure_Cognitive_Services.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1neX6x9IxTUyj9Rt50jVHsOzhh3rKwJus

Step 1: Set Up Microsoft Azure Cognitive Services and mount google drive to access files
"""

# Mount Google Drive to access files
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# Set the path to your receipt images folder in Google Drive
image_url = '/content/drive/My Drive/Receipt_images/'

"""Step 2: Library installations"""

!pip install azure-ai-formrecognizer azure-cognitiveservices-vision-computervision

!pip install azure-ai-textanalytics

"""Step 3: Authenticate with Microsoft Azure"""

from azure.core.credentials import AzureKeyCredential
from azure.ai.textanalytics import TextAnalyticsClient
from azure.cognitiveservices.vision.computervision import ComputerVisionClient
from msrest.authentication import CognitiveServicesCredentials

# Replace with your Azure Text Analytics API key and endpoint
text_analytics_key = "af427980734f46bb8248df6de21c9f41"
text_analytics_endpoint = "https://kolapo-o.cognitiveservices.azure.com/"

# Replace with your Azure Computer Vision API key and endpoint
computer_vision_key = "265e2e01bd0f4c1589994e146bdf5cbd"
computer_vision_endpoint = "https://alright.cognitiveservices.azure.com/"

# Create Text Analytics and Computer Vision clients
text_analytics_client = TextAnalyticsClient(text_analytics_endpoint, AzureKeyCredential(text_analytics_key))
computer_vision_client = ComputerVisionClient(computer_vision_endpoint, CognitiveServicesCredentials(computer_vision_key))

!pip install Pillow

"""Step 4: Extract Text from Receipt Images and classify texts into entities"""

from PIL import Image
import io
import os
def extract_text_from_images(folder_path):
    all_texts = []
    for filename in os.listdir(folder_path):
        image_path = os.path.join(folder_path, filename)

        with open(image_path, "rb") as image_stream:
            # Open the image using PIL to get its size
            img = Image.open(image_stream)
            width, height = img.size

            print(f"Original Image Size: {width} x {height}")

            # Resize the image if its dimensions are outside the supported range
            if width > 1000 or height > 1000:
                img = img.resize((1000, 1000))

            # Convert the image to bytes
            image_stream = io.BytesIO()
            img.save(image_stream, format="PNG")
            image_stream.seek(0)

            result = computer_vision_client.recognize_printed_text_in_stream(image_stream)
            image_texts = []

            for region in result.regions:
                for line in region.lines:
                    for word in line.words:
                        image_texts.append(word.text)

            all_texts.append({"filename": filename, "text": image_texts})

    return all_texts

def classify_entities(all_texts):
    for image_result in all_texts:
        documents = [" ".join(image_result["text"])]

        if documents[0].strip():  # Check if document text is not empty
            response = text_analytics_client.recognize_entities(documents, language="en")

            entities = []
            for entity in response[0].entities:
                entities.append({"text": entity.text, "category": entity.category})

            image_result["entities"] = entities
        else:
            image_result["entities"] = []  # Handle empty document text

# Replace with your Google Drive folder path
folder_path = "/content/drive/My Drive/Receipt_images/"
all_extracted_texts = extract_text_from_images(folder_path)

classify_entities(all_extracted_texts)

# Print the extracted information
for image_result in all_extracted_texts:
    print(f"Text extracted from {image_result['filename']}:\n{image_result['text']}\n")
    print(f"Entities:\n{image_result['entities']}\n")

print(f"Extracted information has been saved to: {json_output_path}")

for image_result in all_extracted_texts:
    print(f"Text extracted from {image_result['filename']}:\n{image_result['text']}\n")
    print(f"Entities:\n{image_result['entities']}\n")

"""store the extracted file as json"""

import os
from PIL import Image
import io
import json

# ... (Previous code for imports and client authentication)

def extract_text_from_images(folder_path):
    all_texts = []
    for filename in os.listdir(folder_path):
        image_path = os.path.join(folder_path, filename)

        with open(image_path, "rb") as image_stream:
            # Open the image using PIL to get its size
            img = Image.open(image_stream)
            width, height = img.size

            print(f"Original Image Size: {width} x {height}")

            # Resize the image if its dimensions are outside the supported range
            if width > 1000 or height > 1000:
                img = img.resize((1000, 1000))

            # Convert the image to bytes
            image_stream = io.BytesIO()
            img.save(image_stream, format="PNG")
            image_stream.seek(0)

            result = computer_vision_client.recognize_printed_text_in_stream(image_stream)
            image_texts = []

            for region in result.regions:
                for line in region.lines:
                    for word in line.words:
                        image_texts.append(word.text)

            all_texts.append({"filename": filename, "text": image_texts})

    return all_texts

def classify_entities(all_texts):
    for image_result in all_texts:
        documents = [" ".join(image_result["text"])]

        if documents[0].strip():  # Check if document text is not empty
            response = text_analytics_client.recognize_entities(documents, language="en")

            entities = []
            for entity in response[0].entities:
                entities.append({"text": entity.text, "category": entity.category})

            image_result["entities"] = entities
        else:
            image_result["entities"] = []  # Handle empty document text

# Replace with your Google Drive folder path
folder_path = "/content/drive/My Drive/Receipt_images/"
all_extracted_texts = extract_text_from_images(folder_path)

classify_entities(all_extracted_texts)

# Store the extracted information as JSON
json_output_path = "/content/drive/My Drive/extracted_information.json"
with open(json_output_path, "w") as json_file:
    json.dump(all_extracted_texts, json_file, indent=4)

# Print the extracted information
for image_result in all_extracted_texts:
    print(f"Text extracted from {image_result['filename']}:\n{image_result['text']}\n")
    print(f"Entities:\n{image_result['entities']}\n")

print(f"Extracted information has been saved to: {json_output_path}")

"""Step 5: Entity analysis"""

import matplotlib.pyplot as plt
from collections import Counter

# Extract entity types information from the results
all_entity_types = [entity['category'] for image_result in all_extracted_texts for entity in image_result['entities']]

# Count the occurrences of each entity type
entity_type_counts = Counter(all_entity_types)

# Sort the entity types by count in descending order
sorted_entity_types = sorted(entity_type_counts.items(), key=lambda x: x[1], reverse=True)

# Extract labels and counts for the chart
labels, counts = zip(*sorted_entity_types)

# Plot the bar chart
fig, ax = plt.subplots(figsize=(12, 6))
ax.bar(labels, counts, color='magenta')

ax.set_ylabel('Number of Occurrences')
ax.set_title('Distribution of Entity Types Across Images')
ax.set_xlabel('Entity Types')
ax.tick_params(axis='x', rotation=45, labelsize=10)

# Optionally, limit the number of displayed entity types for clarity
# ax.set_xticks(labels[:10])  # Adjust the number as needed

plt.show()